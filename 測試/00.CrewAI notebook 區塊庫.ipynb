{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCrewAI 支援 openAI gemini ollama\\n其他本地端大模型待測試\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CrewAI 支援 openAI gemini ollama\n",
    "其他本地端大模型待測試\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入依賴庫\n",
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import HTML, display, Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定4個 LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.llms import OpenAI, Ollama\n",
    "from langchain_openai import ChatOpenAI\n",
    "# crewai 使用 Ollama 的方法：ollama 已推出 windows 版本，不需要執行 litellm；Mac 則也不需要啟動任何程式，只要有安裝好 Ollama 即可調用。\n",
    "# (autogen 要調用 Ollama 需要執行 litellm，多一道步驟，比較麻煩)\n",
    "gpt35 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7),\n",
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7),\n",
    "# Ollama 大模型，用 modelfile 建立的，可以在 modelfile 設定溫度，但切勿在系統提示詞要它使用中文回復，會造成函數調用不正常\n",
    "ollama = Ollama(model=\"openhermes\")\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             verbose = True,\n",
    "                             temperature = 0.6,\n",
    "                             google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定工具 tools\n",
    "# Make sure to Install duckduckgo-search for this example:\n",
    "# !pip install -U duckduckgo-search\n",
    "# 最簡易型的工具定義方式\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# 從 tools 模組中引入需要的工具\n",
    "from tools.browser_tools import BrowserTools\n",
    "from tools.calculator_tools import CalculatorTools\n",
    "from tools.file_tools import FileTools\n",
    "from tools.search_tools import SearchTools\n",
    "from tools.sec_tools import SECTools\n",
    "# 下面添加 tools 時，必須用 類別.方法 加入工具\n",
    "# BrowserTools.scrape_and_summarize_website\n",
    "# CalculatorTools.calculate\n",
    "# FileTools.write_file\n",
    "# SearchTools.search_internet、SearchTools.search_news\n",
    "# SECTools.search_10q、SECTools.search_10k\n",
    "# 下面的是依樣畫葫蘆自行加入2行定義類別，親測可以匯入\n",
    "from tools.find_papers_arxiv import FindPapersArxiv\n",
    "from tools.get_top_hackernews_stories import GetTopHackernewsStories\n",
    "# 然後就可以用下面的函式來使用工具，已測試可以~~~\n",
    "# FindPapersArxiv.search_arxiv\n",
    "# GetTopHackernewsStories.get_top_hackernews_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your agents with roles and goals\n",
    "# allow_delegation=True, 打開測試看看\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge developments in AI and data science',\n",
    "  backstory=\"\"\"You work at a leading tech think tank.\n",
    "  Your expertise lies in identifying emerging trends.\n",
    "  You have a knack for dissecting complex data and presenting\n",
    "  actionable insights.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  tools=[\n",
    "        search_tool, \n",
    "        BrowserTools.scrape_and_summarize_website, \n",
    "        CalculatorTools.calculate, \n",
    "        FileTools.write_file,\n",
    "        SearchTools.search_internet, SearchTools.search_news,\n",
    "        SECTools.search_10q, SECTools.search_10k,\n",
    "        FindPapersArxiv.search_arxiv,\n",
    "        GetTopHackernewsStories.get_top_hackernews_stories\n",
    "      ],\n",
    "  # You can pass an optional llm attribute specifying what mode you wanna use.\n",
    "  # It can be a local model through Ollama / LM Studio or a remote\n",
    "  # model like OpenAI, Mistral, Antrophic of others (https://python.langchain.com/docs/integrations/llms/)\n",
    "  #\n",
    "  # Examples:\n",
    "  # llm=ollama # was defined above in the file\n",
    "  # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\n",
    "  # llm = gemini  #using google gemini pro API\n",
    "  # 或在定義後，使用 researcher.llm = ollama 或 gemini 來更改模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寫手應該不需要掛太多 tools，單純測試看看。\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft compelling content on tech advancements',\n",
    "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
    "  your insightful and engaging articles.\n",
    "  You transform complex concepts into compelling narratives.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  tools=[\n",
    "        search_tool, \n",
    "        BrowserTools.scrape_and_summarize_website, \n",
    "        CalculatorTools.calculate, \n",
    "        FileTools.write_file,\n",
    "        SearchTools.search_internet, SearchTools.search_news,\n",
    "        SECTools.search_10q, SECTools.search_10k,\n",
    "        FindPapersArxiv.search_arxiv,\n",
    "        GetTopHackernewsStories.get_top_hackernews_stories\n",
    "      ],\n",
    "  # llm = gemini  #using google gemini pro API\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面可以先不指定用哪一個 llm，這裡再指定就可以\n",
    "# 但是如果分 main.py、agents.py、tasks.py 三個檔案，就必須先指定用哪一個 llm\n",
    "researcher.llm = ollama\n",
    "writer.llm = ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tasks for your agents\n",
    "# 跟 phidata 比較，phidata 有提供 cli 命令交互式的方法，透過交互式的方式，可以讓使用者在命令列輸入文字，並回傳答案。\n",
    "# 但 crewai 必須在程式碼中定義好要執行的任務 tasks，並執行任務。\n",
    "# 要 AI 解決任務，就必須透過程式碼內輸入 tasks 的任務內容，並執行程式，才能得到結果。\n",
    "task1 = Task(\n",
    "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
    "  Identify key trends, breakthrough technologies, and potential industry impacts.\n",
    "  Your final answer MUST be a full analysis report\"\"\",\n",
    "  agent=researcher\n",
    ")\n",
    "task2 = Task(\n",
    "  description=\"\"\"Using the insights provided, develop an engaging blog\n",
    "  post that highlights the most significant AI advancements.\n",
    "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
    "  Make it sound cool, avoid complex words so it doesn't sound like AI.\n",
    "  Your final answer MUST be the full blog post of at least 5 paragraphs.\"\"\",\n",
    "  agent=writer\n",
    ")\n",
    "task3 = Task(\n",
    "  description=\"\"\"express the final blog post provided in traditional chinese。 and write it to a file AI_2024.md\"\"\",\n",
    "  agent=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[task1, task2, task3],\n",
    "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG]: Working Agent: Senior Research Analyst\n",
      "[INFO]: Starting Task: Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
      "  Identify key trends, breakthrough technologies, and potential industry impacts.\n",
      "  Your final answer MUST be a full analysis report\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mUse Tool: duckduckgo_search\n",
      "Search the internet: \"latest advancements in AI 2024\"\u001b[0m\u001b[93m \n",
      "\n",
      "In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI... 10 top AI and machine learning trends for 2024 Custom enterprise models, open source AI, multimodal -- learn about the top AI and machine learning trends for 2024 and how they promise to transform the industry. By Lev Craig, Site Editor Published: 04 Jan 2024 As 2024 unfolds, we will see monumental leaps in AI capabilities, especially in areas demanding complex problem-solving fueled by quantum advancements. published 27 December 2023 While 2023 was the year of AI, 2024 will be the year we use it. (Image credit: Aston Martin/Apple) We have just come to the end of a year where artificial... Artificial intelligence AI for everything: 10 Breakthrough Technologies 2024 Generative AI tools like ChatGPT reached mass adoption in record time, and reset the course of an entire industry....\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "# crew\n",
    "# Get your crew to work!\n",
    "result = crew.kickoff()\n",
    "# print(result)\n",
    "to_markdown(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
