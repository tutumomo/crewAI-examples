{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "# os.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\n",
    "\n",
    "\n",
    "# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.\n",
    "# os.environ[\"OPENAI_API_BASE\"] = 'http://localhost:11434/v1'\n",
    "# os.environ[\"OPENAI_MODEL_NAME\"] ='openhermes'  # Adjust based on available model\n",
    "# os.environ[\"OPENAI_API_KEY\"] ='sk-111111111111111111111111111111111111111111111111'\n",
    "OPENAI_API_BASE= 'http://localhost:11434/v1'\n",
    "OPENAI_MODEL_NAME=\"llama3_function\"\n",
    "OPENAI_API_KEY='sk-111111111111111111111111111111111111111111111111'\n",
    "\"\"\"\n",
    "# 設定4個 LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.llms import OpenAI, Ollama\n",
    "from langchain_openai import ChatOpenAI\n",
    "# crewai 使用 Ollama 的方法：windows 只需要打開 ubuntu 視窗即可，不需要執行 litellm；Mac 則甚至不需要啟動任何程式，只要有安裝好 Ollama 即可調用。\n",
    "# 與 autogen 不同，autogen 要調用 Ollama 需要執行 litellm，多一道步驟，比較麻煩\n",
    "gpt35 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7),\n",
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7),\n",
    "# Ollama 大模型，可以看要用哪一個\n",
    "# ollama = Ollama(model=\"openhermes_assistant\")  # 這是用 modelfile 建立的\n",
    "# ollama 2024/03/12 最強大模型 nous-hermes2\n",
    "ollama = Ollama(model=\"llama3_function\")\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             verbose = True,\n",
    "                             temperature = 0.6,\n",
    "                             google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "                             )\n",
    "# =========================\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "from langchain_community.llms import OpenAI, Ollama\n",
    "ollama = Ollama(model=\"llama3_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = SerperDevTool()\n",
    "\n",
    "# Define your agents with roles and goals\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge developments in AI and data science',\n",
    "  backstory=\"\"\"You work at a leading tech think tank.\n",
    "  Your expertise lies in identifying emerging trends.\n",
    "  You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[search_tool]\n",
    "  # You can pass an optional llm attribute specifying what model you wanna use.\n",
    "  # It can be a local model through Ollama / LM Studio or a remote\n",
    "  # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\n",
    "  #\n",
    "  # import os\n",
    "  # os.environ['OPENAI_MODEL_NAME'] = 'gpt-3.5-turbo'\n",
    "  #\n",
    "  # OR\n",
    "  #\n",
    "  # from langchain_openai import ChatOpenAI\n",
    "  # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\n",
    ")\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft compelling content on tech advancements',\n",
    "  backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n",
    "  You transform complex concepts into compelling narratives.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher.llm=ollama\n",
    "writer.llm=ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tasks for your agents\n",
    "task1 = Task(\n",
    "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
    "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
    "  expected_output=\"Full analysis report in bullet points\",\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Using the insights provided, develop an engaging blog\n",
    "  post that highlights the most significant AI advancements.\n",
    "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
    "  Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n",
    "  expected_output=\"Full blog post of at least 5 paragraphs. Andwrite in traditional chinese.\",\n",
    "  agent=writer\n",
    ")\n",
    "\n",
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[task1, task2],\n",
    "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
    ")\n",
    "\n",
    "# Get your crew to work!\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"######################\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
